{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from vietocr.tool.config import Cfg\n",
    "from vietocr.model.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Cfg.load_config_from_name('vgg_transformer')\n",
    "dataset_params = {\n",
    "    'name':'imgVietocr',\n",
    "    'data_root':'/mnt/disk1/mbbank/OCR/DATA/data_quangnd/new_train',\n",
    "    'train_annotation':'/mnt/disk1/mbbank/OCR/DATA/team/train.txt',\n",
    "    'valid_annotation':'/mnt/disk1/mbbank/OCR/DATA/team/val.txt'\n",
    "}\n",
    "\n",
    "params = {\n",
    "         'print_every':200,\n",
    "         'valid_every':2*200,\n",
    "          'iters':2000000,\n",
    "          'checkpoint':'/mnt/disk1/mbbank/OCR/CODE/VietOcr/weight/vietocr_V1.pth',\n",
    "          'export':'/mnt/disk1/mbbank/OCR/CODE/VietOcr/weight/vietocr_V2.pth',\n",
    "          'metrics': 150\n",
    "         }\n",
    "\n",
    "config['trainer'].update(params)\n",
    "config['dataset'].update(dataset_params)\n",
    "config['vocab'] += '–' + 'ü' + 'ā' + 'ö' # Ko cần dòng này, nếu cần thì thêm các kí tự\n",
    "config['device'] = 'cuda:0'\n",
    "config['optimizer']['max_lr'] = 0.00005\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config, pretrained=False)\n",
    "trainer.config.save('/mnt/disk1/mbbank/OCR/CODE/VietOcr/vietocr/config/config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.visualize_dataset()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.visualize_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN VOCAB 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'public_test_img_11348.jpg': (['quị', 'quị'], 'quị'),\n",
       " 'public_test_img_22272.png': (['phấp', 'nhấp'], 'phấp')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  sys\n",
    "sys.path.append('/mnt/disk1/mbbank/OCR/CODE/VietOcr')\n",
    "\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.translate import translate_full_prob\n",
    "from vietocr.tool.config import Cfg\n",
    "sys.path.append('../')\n",
    "from Preprocessing.skew import SkewCorrection\n",
    "from Preprocessing.perspective import PerspectiveCorrection\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "class RECOGNIZE():\n",
    "    def __init__(self, weight_path='./weight/vietocr_v1.pth', \n",
    "                 config_path = '/mnt/disk1/mbbank/OCR/CODE/VietOcr/config/config_V5.yml',\n",
    "                 device='cpu') -> None:\n",
    "        config = Cfg.load_config_from_file(config_path)\n",
    "        config['weights'] = weight_path\n",
    "        config['cnn']['pretrained'] = False\n",
    "        config['device'] = device\n",
    "        config['predictor']['beamsearch'] = False\n",
    "        self.config = config\n",
    "        self.detector = Predictor(config)\n",
    "    \n",
    "    def predict_image(self, img_path, preprocess=False):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if preprocess:\n",
    "            img_np = np.array(img)\n",
    "            img_corrected = PerspectiveCorrection(img_np)\n",
    "            img_pil = Image.fromarray(img_corrected)\n",
    "        else:\n",
    "            img_pil = img\n",
    "            \n",
    "        words_predicted, full_prob = self.detector.predict(img_pil, full_seq=True)\n",
    "        \n",
    "        # s, probs =  translate_full_prob(full_prob)\n",
    "        # words_predicted_dulp = self.detector.vocab.decode(s.tolist())\n",
    "        # print('dulp', words_predicted_dulp)\n",
    "        \n",
    "        return words_predicted\n",
    "    \n",
    "class RECOGNIZE_ENSEMBLE():\n",
    "    def __init__(self, weight_paths=['./weight/vietocr_v3.pth'], \n",
    "                 config_path = '/mnt/disk1/mbbank/OCR/CODE/VietOcr/config/config_V3.yml',\n",
    "                 device='cpu') -> None:\n",
    "        config = Cfg.load_config_from_file(config_path)\n",
    "        config['cnn']['pretrained'] = False\n",
    "        config['device'] = device\n",
    "        config['predictor']['beamsearch'] = False\n",
    "        print('LEN VOCAB' ,len(config['vocab']))\n",
    "        self.config = config\n",
    "        self.detectors = []\n",
    "        for weight_path in weight_paths:\n",
    "            config['weights'] = weight_path\n",
    "            self.detectors.append(Predictor(config))\n",
    "\n",
    "    \n",
    "    def predict_image(self, img_path, preprocess=False):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if preprocess:         \n",
    "            img_np = np.array(img)\n",
    "            img_corrected = PerspectiveCorrection(img_np)\n",
    "            img_pil = Image.fromarray(img_corrected)\n",
    "        else:\n",
    "            img_pil = img\n",
    "            \n",
    "        n = len(self.detectors)\n",
    "        words_predicted_list = []\n",
    "        full_prob = None\n",
    "        for detector in self.detectors:\n",
    "            words_predicted, output = detector.predict(img_pil, full_seq=True)\n",
    "            words_predicted_list.append(words_predicted)\n",
    "            if full_prob is None:  \n",
    "                full_prob = output/n\n",
    "            else:\n",
    "                full_prob += output/n\n",
    "\n",
    "        s, probs =  translate_full_prob(full_prob)\n",
    "        words_predicted_ensemble = self.detectors[0].vocab.decode(s.tolist())\n",
    "        return words_predicted_list, words_predicted_ensemble\n",
    "\n",
    "weight1 = '/mnt/disk1/mbbank/OCR/CODE/VietOcr/weight/vietocr_V3.pth'\n",
    "weight2 = '/mnt/disk1/mbbank/OCR/CODE/VietOcr/weight/vietocr_V2.pth'\n",
    "config_path = '/mnt/disk1/mbbank/OCR/CODE/VietOcr/config/config_V3.yml'\n",
    "model_v1 = RECOGNIZE_ENSEMBLE(weight_paths=[weight1, weight2], \n",
    "                              config_path=config_path,device='cuda:2')\n",
    "\n",
    "v1_predict = {}\n",
    "org_test = '/mnt/disk1/mbbank/OCR/DATA/data_quangnd/test'\n",
    "bar = tqdm(os.listdir(org_test)[1000:1002])\n",
    "for img_path in  bar:\n",
    "    v1_predict[img_path] = model_v1.predict_image(org_test + '/' + img_path, \n",
    "                                                  preprocess=False)\n",
    "v1_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = '/mnt/disk1/mbbank/OCR/CODE/VietOcr/weight/vietocr_V3.pth'\n",
    "model_v1 = RECOGNIZE(weight_path=weight, device='cuda:2')\n",
    "\n",
    "v1_predict = {}\n",
    "org_test = '/mnt/disk1/mbbank/OCR/DATA/data_quangnd/test'\n",
    "bar = tqdm(os.listdir(org_test)[0:2])\n",
    "for img_path in  bar:\n",
    "    v1_predict[img_path] = model_v1.predict_image(org_test + '/' + img_path, \n",
    "                                                  preprocess=False)\n",
    "\n",
    "# with open('/mnt/disk1/mbbank/OCR/CODE/VietOcr/puplictest_infer/vietocr_V3_beamsearch_perspective.txt', 'w') as f:\n",
    "#     for key, value in v1_predict.items():\n",
    "#         f.write('%s\\t%s\\n' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = org_test + '/' + 'public_test_img_10774.jpg'\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "plt.imshow(image)       \n",
    "plt.title(v1_predict['public_test_img_10774.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/mnt/disk1/mbbank/OCR/CODE/VietOcr/puplictest_infer/vietocr_V3_beamsearch_perspective.txt', 'r') as f:\n",
    "     lines = f.readlines()\n",
    "for cnt, line in enumerate(lines):\n",
    "     print(cnt, line.strip())\n",
    "     command, description = line.strip().split(None, 1)\n",
    "     print(cnt, command, description)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
